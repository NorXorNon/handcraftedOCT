{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HPreprocess as P\n",
    "import HDataset as D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy import linalg as LA\n",
    "from numpy.random import permutation\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "ref = random.sample(range(10000, 40000),1)[0]\n",
    "\n",
    "data = D.txt_to_var('test250.txt')\n",
    "x_train = data[500:2200]\n",
    "x_test = data[2500:3500]\n",
    "\n",
    "def balance_data(dataRaw):\n",
    "    label,train = zip(*dataRaw)\n",
    "    labelf = [0 if i=='2' else 1 for i in label]\n",
    "    nr = np.array(list(set(zip(labelf,train))))\n",
    "    dataone = [data for data in nr if data[0]=='1']\n",
    "    datazero = [data for data in nr if data[0]=='0']\n",
    "    dataone = dataone[:len(datazero)]\n",
    "    dataall = dataone + datazero\n",
    "    permutation(dataall)\n",
    "    return dataall\n",
    "\n",
    "def feature_extract(img,nfea=300):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create(nfeatures = nfea,\n",
    "    scaleFactor = 1.2,\n",
    "    nlevels = 8,\n",
    "    edgeThreshold = 15,\n",
    "    firstLevel = 1,\n",
    "    WTA_K = 2,\n",
    "    patchSize = 30,\n",
    "    fastThreshold = 10 \n",
    "    )\n",
    "\n",
    "    kp = orb.detect(img,None)\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    des = np.array(des)\n",
    "    if(des.shape[0] != nfea):\n",
    "        des = np.concatenate((des,np.zeros(((nfea-des.shape[0],32)))),axis=0)\n",
    "    scaler = StandardScaler()\n",
    "    desf_s = scaler.fit_transform(des)\n",
    "    return desf_s\n",
    "    \n",
    "xxxxxx    \n",
    "x_train = balance_data(x_train)\n",
    "\n",
    "xtrain, ytrain_label = D.single_fit(data=x_train,shape=(224,224),shuffleIm=True,num_class=2 )\n",
    "\n",
    "xtrainCanny = xtrain.copy()\n",
    "\n",
    "    \n",
    "#xtrain_vec = [i.flatten() for i in xtrain]\n",
    "orbfeature_train = list()\n",
    "for i in range(len(xtrain)):\n",
    "    orbfeature_train.append(feature_extract(img=xtrain[i],nfea=200))\n",
    "    \n",
    "orbfeature_train_vec = np.array([i.flatten() for i in orbfeature_train])\n",
    "\n",
    "\n",
    "pca = PCA(n_components=1500)\n",
    "pca_train_result = pca.fit_transform(orbfeature_train_vec)   \n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500)\n",
    "forest.fit(pca_train_result, ytrain_label)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=50)\n",
    "neigh.fit(pca_train_result, ytrain_label) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "datat = D.txt_to_var('test250.txt')\n",
    "xtest, ytest_label = D.single_fit(data=datat,shape=(224,224),shuffleIm=True,num_class=4 )\n",
    "\n",
    "yadap = ytest_label.argmax(-1)\n",
    "yadap = [0 if i==2 else 1 for i in yadap]\n",
    "yadap = np.array(yadap).astype('uint8')\n",
    "\n",
    "\n",
    "neigho = open('savedmodel/neigh_model_34209.sav','rb')\n",
    "foresto = open('savedmodel/forest_model_34209.sav','rb')\n",
    "pca = PCA(n_components=1500)\n",
    "neigh = pickle.load(neigho)\n",
    "forest = pickle.load(foresto)\n",
    "\n",
    "orbfeature_test = list()\n",
    "for i in range(len(xtest)):\n",
    "    orbfeature_test.append(feature_extract(img=xtest[i],nfea=200))\n",
    "    \n",
    "orbfeature_test_vec = np.array([i.flatten() for i in orbfeature_test])\n",
    "pca_test_result = pca.fit_transform(orbfeature_test_vec)  \n",
    "\n",
    "forest_test_softpredictions = forest.predict_proba(pca_test_result)\n",
    "neigh_test_softpredictions = neigh.predict_proba(pca_test_result)\n",
    "\n",
    "\n",
    "forest_test_predictions = forest.predict(pca_test_result)\n",
    "neigh_test_predictions = neigh.predict(pca_test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(orbfeature_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first network with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import numpy\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=798, activation='relu'))\n",
    "model.add(Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(Dense(32,  activation='relu'))\n",
    "model.add(Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(Dense(1,  activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(pca_train_result, ytrain_label[:,1], epochs=30, batch_size=32)\n",
    "# calculate predictions\n",
    "predictions = model.predict(pca_test_result, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(forest_test_predictions.argmax(-1),yadap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def mulit_roc_plot(yTrue,yPred,numClass):\n",
    "    n_classes =numClass\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(yTrue[:, i], yPred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    colors = ['blue', 'red', 'green','yellow','orange']\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, \n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for multi-class data')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "mulit_roc_plot(yTrue=yadap,yPred=,numClass=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(yadap, forest_test_softpredictions[1][:,1].reshape(-1,1))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr,tpr,label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                 ''.format(i, roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
